{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wavelets as wl\n",
    "from scipy import signal\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a dictionary with mice's experiment information and another with the spiking activity in h5py format  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing wild-types\n",
      "Loading SERT1597\n",
      "Loaded /home/maspe/filer/SERT/SERT1597/spikes/results/\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'IDs_KO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-57c60b769ae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mall_info_KO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mall_mice_KO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mID\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mIDs_KO\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mnpys_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/maspe/filer/SERT/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mID\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/npys/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mspikes_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/maspe/filer/SERT/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mID\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/spikes/results/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IDs_KO' is not defined"
     ]
    }
   ],
   "source": [
    "# List of mice, classified by condition\n",
    "IDs_WT = ['SERT1597'] #, 'SERT1659', 'SERT1678', 'SERT1908', 'SERT1984', 'SERT1985', 'SERT2014']\n",
    "#IDs_KO = ['SERT1668'] #, 'SERT1665', 'SERT2013', 'SERT2018', 'SERT2024']\n",
    "\n",
    "# Dictionaries to collect info about the experiment and spiking activity\n",
    "all_info_WT = {}\n",
    "all_mice_WT = {}\n",
    "\n",
    "\n",
    "print('Processing wild-types')\n",
    "for ID in IDs_WT:\n",
    "    npys_dir = '/home/maspe/filer/SERT/' + ID + '/npys/'\n",
    "    spikes_dir = '/home/maspe/filer/SERT/' + ID + '/spikes/results/'\n",
    "    \n",
    "    print('Loading ' + ID)\n",
    "    with open(npys_dir + ID + '.info', 'rb') as f:\n",
    "        info = pickle.load(f)\n",
    "    \n",
    "    # Put the info of this mouse into de info dictionary\n",
    "    all_info_WT[ID] = info\n",
    "    channels = info['channels_list']\n",
    "    \n",
    "    fit = []\n",
    "    for channel in channels:\n",
    "        path = spikes_dir + channel + '.result.hdf5'\n",
    "    \n",
    "        # Get the spiking activity from the h5py file\n",
    "        fit.append(h5py.File(path, 'r'))\n",
    "        \n",
    "    print('Loaded ' + spikes_dir)\n",
    "     \n",
    "    # Put the spiking activity of this mouse into the spiking dictionary\n",
    "    all_mice_WT[ID] = fit\n",
    "\n",
    "    \n",
    "# Same for KO mice\n",
    "#print('Processing knock-out')\n",
    "all_info_KO = {}\n",
    "all_mice_KO = {}\n",
    "for ID in IDs_KO:\n",
    "    npys_dir = '/home/maspe/filer/SERT/' + ID + '/npys/'\n",
    "    spikes_dir = '/home/maspe/filer/SERT/' + ID + '/spikes/results/'\n",
    "    \n",
    "    print('Loading ' + ID)\n",
    "    with open(npys_dir + ID + '.info', 'rb') as f:\n",
    "        info = pickle.load(f)\n",
    "\n",
    "    all_info_KO[ID] = info\n",
    "    channels = info['channels_list']\n",
    "    \n",
    "    fit = []\n",
    "    for channel in channels:\n",
    "        path = spikes_dir + channel + '.result.hdf5'\n",
    "    \n",
    "        fit.append(h5py.File(path, 'r'))\n",
    "        \n",
    "    print('Loaded ' + spikes_dir)\n",
    "        \n",
    "    all_mice_KO[ID] = fit\n",
    "\n",
    "    \n",
    "# all_mice_WT['SERT1597'][0]['spiketimes']['temp_0'][()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create one dictionary with the ID of each channell and another with the spike times for all units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_units_WT = {}\n",
    "all_channels_WT = {}\n",
    "for mouse in all_mice_WT.keys():\n",
    "    n_channels = 32\n",
    "    units = []\n",
    "    channels_id = []\n",
    "    \n",
    "    iteration = 0\n",
    "    for channel in range(n_channels):\n",
    "        for unit in all_mice_WT[mouse][channel]['spiketimes'].keys():\n",
    "            units.append(all_mice_WT[mouse][channel]['spiketimes'][unit][()]) # Final \"[()]\" is to import values from h5py \n",
    "      \n",
    "            channels_id.append(all_info_WT[mouse]['channels_locs'][iteration])\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "            \n",
    "    all_units_WT[mouse] = units\n",
    "    all_channels_WT[mouse] = channels_id\n",
    "        \n",
    "# print('n units = %i' %len(all_units))\n",
    "\n",
    "\n",
    "all_units_KO = {}\n",
    "all_channels_KO = {}\n",
    "for mouse in all_mice_KO.keys():\n",
    "    n_channels = 32\n",
    "    units = []\n",
    "    channels_id = []\n",
    "    \n",
    "    iteration = 0\n",
    "    for channel in range(n_channels):\n",
    "        for unit in all_mice_KO[mouse][channel]['spiketimes'].keys():\n",
    "            units.append(all_mice_KO[mouse][channel]['spiketimes'][unit][()]) # Final \"[()]\" is to import values from h5py \n",
    "      \n",
    "            channels_id.append(all_info_KO[mouse]['channels_locs'][iteration])\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "            \n",
    "    all_units_KO[mouse] = units\n",
    "    all_channels_KO[mouse] = channels_id\n",
    "        \n",
    "# print('n units = %i' %len(all_units))\n",
    "# all_units_WT['SERT1597']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "47966705 / 30000 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "19382520 / 30000 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.int(all_info_WT[mouse]['startOF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "17550000 / 30000 / 60.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the windows of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are currently using a time windows of 2 minutes that finishes 15 seconds before the beginning of the OF, for the HC condition; and a time windows that begins 15 seconds after the beginning of the OF, and extends to minute 10 (total length: 9.75 min)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS CAN BE MOVED TO THE CREATION OF INFO FILES!!! ###\n",
    "### Extract a windows of n_secs length at the beginning and end of the task\n",
    "n_min = 2\n",
    "exclude_sec = 15\n",
    "sample_rate = 30000\n",
    "#window = int(sampleRate * secs)\n",
    "n_points = 30000 * 60 * 10 # Length of the OF\n",
    "window = sample_rate * n_min * 60 # 2 min windows\n",
    "exclude_window = sample_rate * exclude_sec # 15 sec windows to exclude at the HC-OF transition\n",
    "\n",
    "all_epochs_WT = {}\n",
    "all_perispikes_WT = {}\n",
    "for mouse in all_mice_WT.keys():\n",
    "    stopHC = np.int(all_info_WT[mouse]['startOF']) - exclude_window\n",
    "    startHC = stopHC - window\n",
    "    \n",
    "    startOF = np.int(all_info_WT[mouse]['startOF']) + exclude_window\n",
    "    stopOF = startOF + n_points - exclude_window\n",
    "    \n",
    "    baseline = np.arange(startHC, stopHC, 1)\n",
    "    task = np.arange(startOF, stopOF, 1)\n",
    "    \n",
    "    complete_window = np.concatenate([baseline, task])\n",
    "    all_epochs_WT[mouse] = complete_window\n",
    "    \n",
    "\n",
    "all_epochs_KO = {}\n",
    "all_perispikes_KO = {}\n",
    "for mouse in all_mice_KO.keys():\n",
    "    stopHC = np.int(all_info_KO[mouse]['startOF']) - exclude_window\n",
    "    startHC = stopHC - window\n",
    "    \n",
    "    startOF = np.int(all_info_KO[mouse]['startOF']) + exclude_window\n",
    "    stopOF = startOF + n_points - exclude_window\n",
    "    \n",
    "    baseline = np.arange(startHC, stopHC, 1)\n",
    "    task = np.arange(startOF, stopOF, 1)\n",
    "    \n",
    "    complete_window = np.concatenate([baseline, task])\n",
    "    all_epochs_KO[mouse] = complete_window\n",
    "\n",
    "\n",
    "task_npoints = complete_window.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the spikes that fall inside the time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mouse SERT1597...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "all_perispikes_WT = {}\n",
    "#npys_dir = '/home/maspe/filer/SERT/ALL/npys/'\n",
    "\n",
    "\n",
    "for mouse in all_mice_WT.keys():\n",
    "    clock = time.time()\n",
    "\n",
    "    all_spikes = all_units_WT[mouse]\n",
    "    peristimulus_spikes = np.zeros((len(all_spikes), task_npoints))   \n",
    "    \n",
    "    print('Processing mouse %s...' % mouse)\n",
    "    \n",
    "    for unit in range(len(all_spikes)):\n",
    "        peristimulus_spikes[unit, :] = np.isin(all_epochs_WT[mouse], all_spikes[unit])#, axes=(1, 0))\n",
    "#         peristimulus_spikes[:, :, ] = np.transpose(np.isin(epochs_matrix, all_spikes[unit]), axes=(0, 2, 1))\n",
    "# #         peristimulus_spikes = np.transpose(np.array(peristimulus_spikes), axes=(0, 2, 1))\n",
    "        \n",
    "    all_perispikes_WT[mouse] = peristimulus_spikes\n",
    "    #np.save(npys_dir + mouse + '_perispikes_WT.npy', peristimulus_spikes)\n",
    "    \n",
    "print('Done in {} s.!'.format(time.time() - clock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 21150000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_perispikes_WT['SERT1597'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_perispikes_KO = {}\n",
    "\n",
    "for mouse in all_mice_KO.keys():\n",
    "    all_spikes = all_units_KO[mouse] \n",
    "    peristimulus_spikes = np.zeros((len(all_spikes), task_npoints))   \n",
    "    \n",
    "    print('Processing mouse %s...' % mouse)\n",
    "\n",
    "    for unit in range(len(all_spikes)):\n",
    "        peristimulus_spikes[unit, :] = np.isin(all_epochs_KO[mouse], all_spikes[unit])\n",
    "        \n",
    "    #np.save(npys_dir + mouse + '_perispikes_KO.npy', peristimulus_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_perispikes_KO.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "npys_dir = '/home/maspe/filer/SERT/ALL/npys/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mice_WT = {'SERT1597': np.load(npys_dir + 'SERT1597_perispikes_WT.npy', allow_pickle=True), \n",
    "               'SERT1659': np.load(npys_dir + 'SERT1659_perispikes_WT.npy', allow_pickle=True),\n",
    "              'SERT1678': np.load(npys_dir + 'SERT1678_perispikes_WT.npy', allow_pickle=True),\n",
    "              'SERT1908': np.load(npys_dir + 'SERT1908_perispikes_WT.npy', allow_pickle=True),\n",
    "              'SERT1984': np.load(npys_dir + 'SERT1984_perispikes_WT.npy', allow_pickle=True),\n",
    "              'SERT1985': np.load(npys_dir + 'SERT1985_perispikes_WT.npy', allow_pickle=True),\n",
    "              'SERT2014': np.load(npys_dir + 'SERT2014_perispikes_WT.npy', allow_pickle=True)}\n",
    "\n",
    "print('Perispikes loaded!\\nAdding spikes...')\n",
    "\n",
    "mPFC_WT = {}\n",
    "NAC_WT  = {}\n",
    "BLA_WT  = {}\n",
    "vHip_WT = {}\n",
    "\n",
    "for mouse in all_mice_WT.keys():\n",
    "    mPFC_WT_indexes  = [i for i,x in enumerate(all_channels_WT[mouse]) if x == 'mPFC_left']\n",
    "    NAC_WT_indexes = [i for i,x in enumerate(all_channels_WT[mouse]) if x == 'NAC_left']\n",
    "    BLA_WT_indexes  = [i for i,x in enumerate(all_channels_WT[mouse]) if x == 'BLA_left']\n",
    "    vHip_WT_indexes  = [i for i,x in enumerate(all_channels_WT[mouse]) if x == 'vHipp_left']\n",
    "    \n",
    "    \n",
    "    mPFC_WT[mouse] = np.sum(all_mice_WT[mouse][mPFC_WT_indexes, :], axis=0)\n",
    "    NAC_WT[mouse] = np.sum(all_mice_WT[mouse][NAC_WT_indexes, :], axis=0)\n",
    "    BLA_WT[mouse] = np.sum(all_mice_WT[mouse][BLA_WT_indexes, :], axis=0)\n",
    "    vHip_WT[mouse] = np.sum(all_mice_WT[mouse][vHip_WT_indexes, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_channels_WT[mouse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npys_dir = '/home/maspe/filer/SERT/ALL/npys/'\n",
    "\n",
    "all_spikes_WT = {'mPFC': mPFC_WT, 'BLA': BLA_WT, 'NAC': NAC_WT, 'vHip': vHip_WT}\n",
    "np.save('/home/maspe/filer/SERT/ALL/npys/all_spikes_WT', all_spikes_WT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels_KO[mouse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npys_dir = '/home/maspe/filer/SERT/ALL/npys/'\n",
    "all_mice_KO = {'SERT1665': np.load(npys_dir + 'SERT1665_perispikes_KO.npy', allow_pickle=True), \n",
    "               'SERT1668': np.load(npys_dir + 'SERT1668_perispikes_KO.npy', allow_pickle=True),\n",
    "              'SERT2013': np.load(npys_dir + 'SERT2013_perispikes_KO.npy', allow_pickle=True),\n",
    "              'SERT2018': np.load(npys_dir + 'SERT2018_perispikes_KO.npy', allow_pickle=True),\n",
    "              'SERT2024': np.load(npys_dir + 'SERT2024_perispikes_KO.npy', allow_pickle=True)}\n",
    "print('Perispikes loaded!\\nAdding spikes...')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mPFC_KO = {}\n",
    "NAC_KO  = {}\n",
    "BLA_KO  = {}\n",
    "vHip_KO = {}\n",
    "\n",
    "for mouse in all_mice_KO.keys():\n",
    "    mPFC_KO_indexes  = [i for i,x in enumerate(all_channels_KO[mouse]) if x == 'mPFC_left']\n",
    "    NAC_KO_indexes = [i for i,x in enumerate(all_channels_KO[mouse]) if x == 'NAC_left']\n",
    "    BLA_KO_indexes  = [i for i,x in enumerate(all_channels_KO[mouse]) if x == 'BLA_left']\n",
    "    vHip_KO_indexes  = [i for i,x in enumerate(all_channels_KO[mouse]) if x == 'vHipp_left']\n",
    "    \n",
    "    \n",
    "    mPFC_KO[mouse] = np.sum(all_mice_KO[mouse][mPFC_KO_indexes, :], axis=0)\n",
    "    NAC_KO[mouse] = np.sum(all_mice_KO[mouse][NAC_KO_indexes, :], axis=0)\n",
    "    BLA_KO[mouse] = np.sum(all_mice_KO[mouse][BLA_KO_indexes, :], axis=0)\n",
    "    vHip_KO[mouse] = np.sum(all_mice_KO[mouse][vHip_KO_indexes, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spikes_KO = {'mPFC': mPFC_KO, 'BLA': BLA_KO, 'NAC': NAC_KO, 'vHip': vHip_KO}\n",
    "np.save('/home/maspe/filer/SERT/ALL/npys/all_spikes_KO', all_spikes_KO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npys_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spikes_WT = np.load('/home/maspe/filer/SERT/ALL/npys/all_spikes_WT.npy', allow_pickle=True).item()\n",
    "all_spikes_WT.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spikes_KO = np.load('/home/maspe/filer/SERT/ALL/npys/all_spikes_KO.npy', allow_pickle=True).item()\n",
    "all_spikes_KO.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmean_WT.shape[0]/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 15000\n",
    "structure = 'vHip'\n",
    "\n",
    "iteration = 0\n",
    "t = np.zeros((len(all_spikes_WT[structure].keys()), 7200000 / factor))\n",
    "for mouse in all_spikes_WT[structure].keys():\n",
    "    t[iteration,:]=np.add.reduceat(all_spikes_WT[structure][mouse],\n",
    "                                   range(0, all_spikes_WT[structure][mouse].shape[0], factor))\n",
    "    \n",
    "    iteration += 1\n",
    "    \n",
    "tmean_WT=np.mean(t, axis=0)\n",
    "tsem_WT=np.std(t, axis=0) / np.sqrt(t.shape[0])\n",
    "\n",
    "iteration = 0\n",
    "t = np.zeros((len(all_spikes_KO[structure].keys()), 7200000 / factor))\n",
    "for mouse in all_spikes_KO[structure].keys():\n",
    "    t[iteration,:]=np.add.reduceat(all_spikes_KO[structure][mouse],\n",
    "                                   range(0, all_spikes_KO[structure][mouse].shape[0], factor))\n",
    "    \n",
    "    iteration += 1\n",
    "    \n",
    "tmean_KO=np.mean(t, axis=0)\n",
    "tsem_KO=np.std(t, axis=0) / np.sqrt(t.shape[0])\n",
    "\n",
    "tx = range(0, tmean_KO.shape[0])\n",
    "\n",
    "\n",
    "### Plot\n",
    "#plt.figure(figsize=(20,10))\n",
    "#plt.subplot(2,2,1)\n",
    "\n",
    "f, (ax, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "ax.plot(tx, tmean_WT, '-', color='blue', alpha=1)\n",
    "ax.fill_between(tx, tmean_WT + tsem_WT, tmean_WT - tsem_WT, alpha=0.5)\n",
    "\n",
    "ax.plot(tx, tmean_KO, '-', color='red', alpha=1)\n",
    "ax.fill_between(tx, tmean_KO + tsem_KO, tmean_KO - tsem_KO, alpha=0.5)\n",
    "\n",
    "ax2.plot(tx, tmean_WT, '-', color='blue', alpha=1)\n",
    "ax2.fill_between(tx, tmean_WT + tsem_WT, tmean_WT - tsem_WT, alpha=0.5)\n",
    "\n",
    "ax2.plot(tx, tmean_KO, '-', color='red', alpha=1)\n",
    "ax2.fill_between(tx, tmean_KO + tsem_KO, tmean_KO - tsem_KO, alpha=0.5)\n",
    "\n",
    "ax.set_xlim(0, 240)  # outliers only\n",
    "ax2.set_xlim(240, 480)  # most of the data\n",
    "\n",
    "ax.set_ylim(0, 2500)  # outliers only\n",
    "\n",
    "\n",
    "# hide the spines between ax and ax2\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax2.spines['left'].set_visible(False)\n",
    "ax.yaxis.tick_left()\n",
    "ax.tick_params(labelright='off')\n",
    "ax2.yaxis.tick_right()\n",
    "\n",
    "d = .02 # how big to make the diagonal lines in axes coordinates\n",
    "# arguments to pass plot, just so we don't keep repeating them\n",
    "kwargs = dict(transform=ax.transAxes, color='k', clip_on=False)\n",
    "ax.plot((1-d,1+d), (-d,+d), **kwargs)\n",
    "ax.plot((1-d,1+d),(1-d,1+d), **kwargs)\n",
    "\n",
    "kwargs.update(transform=ax2.transAxes)  # switch to the bottom axes\n",
    "ax2.plot((-d,+d), (1-d,1+d), **kwargs)\n",
    "ax2.plot((-d,+d), (-d,+d), **kwargs)\n",
    "\n",
    "ax.set_xticklabels(['', '1', '2'], fontsize=14)\n",
    "ax2.set_xticklabels(['7', '8', '9', '10'])\n",
    "\n",
    "ax.tick_params(labelsize=14)\n",
    "ax2.tick_params(labelsize=14)\n",
    "\n",
    "\n",
    "plt.text(380, 2200, structure, fontsize=18)\n",
    "\n",
    "plt.savefig('/home/maspe/filer/SERT/ALL/figs/' + structure + '_perispikes.pdf', dpi=150, facecolor='w', edgecolor='w',\n",
    "            orientation='portrait', papertype=None, format='pdf', transparent=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# NAC\n",
    "iteration = 0\n",
    "t = np.zeros((len(NAC_WT.keys()), window*2 / 60))\n",
    "for mouse in NAC_WT.keys():\n",
    "    t[iteration,:]=np.add.reduceat(NAC_WT[mouse], range(0, NAC_WT[mouse].shape[0], 60))\n",
    "    \n",
    "    iteration += 1\n",
    "    \n",
    "tmean_WT=np.mean(t, axis=0)\n",
    "\n",
    "iteration = 0\n",
    "t = np.zeros((len(NAC_KO.keys()), window*2 / 60))\n",
    "for mouse in NAC_KO.keys():\n",
    "    t[iteration,:]=np.add.reduceat(NAC_KO[mouse], range(0, NAC_KO[mouse].shape[0], 60))\n",
    "    \n",
    "    iteration += 1\n",
    "    \n",
    "tmean_KO=np.mean(t, axis=0)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(tx, tmean_WT, '-', color='blue', alpha=0.7)\n",
    "plt.plot(tx, tmean_KO, '-', color='red', alpha=0.7)\n",
    "plt.xticks([0, 20000, 40000, 60000, 80000, 100000, 120000], ['-3', '-2', '-1', '0', '1', '2', '3'], fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim([0,70])\n",
    "plt.axvline(x=60000, color='black')\n",
    "#plt.xlabel('time (s)')\n",
    "#plt.ylabel('units')\n",
    "plt.title('NAC', fontsize=22)\n",
    "\n",
    "\n",
    "# BLA\n",
    "iteration = 0\n",
    "t = np.zeros((len(BLA_WT.keys()), window*2 / 60))\n",
    "for mouse in BLA_WT.keys():\n",
    "    t[iteration,:]=np.add.reduceat(BLA_WT[mouse], range(0, BLA_WT[mouse].shape[0], 60))\n",
    "    \n",
    "    iteration += 1\n",
    "    \n",
    "tmean_WT=np.mean(t, axis=0)\n",
    "\n",
    "iteration = 0\n",
    "t = np.zeros((len(BLA_KO.keys()), window*2 / 60))\n",
    "for mouse in BLA_KO.keys():\n",
    "    t[iteration,:]=np.add.reduceat(BLA_KO[mouse], range(0, BLA_KO[mouse].shape[0], 60))\n",
    "    \n",
    "    iteration += 1\n",
    "    \n",
    "tmean_KO=np.mean(t, axis=0)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(tx, tmean_WT, '-', color='blue', alpha=0.7)\n",
    "plt.plot(tx, tmean_KO, '-', color='red', alpha=0.7)\n",
    "plt.xticks([0, 20000, 40000, 60000, 80000, 100000, 120000], ['-3', '-2', '-1', '0', '1', '2', '3'], fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim([0,70])\n",
    "plt.axvline(x=60000, color='black')\n",
    "plt.xlabel('time (s)', fontsize=18)\n",
    "plt.ylabel('units', fontsize=18)\n",
    "plt.title('BLA', fontsize=24)\n",
    "\n",
    "\n",
    "# vHip\n",
    "iteration = 0\n",
    "t = np.zeros((len(vHip_WT.keys()), window*2 / 60))\n",
    "for mouse in vHip_WT.keys():\n",
    "    t[iteration,:]=np.add.reduceat(vHip_WT[mouse], range(0, vHip_WT[mouse].shape[0], 60))\n",
    "    \n",
    "    iteration += 1\n",
    "    \n",
    "tmean_WT=np.mean(t, axis=0)\n",
    "\n",
    "iteration = 0\n",
    "t = np.zeros((len(vHip_KO.keys()), window*2 / 60))\n",
    "for mouse in vHip_KO.keys():\n",
    "    t[iteration,:]=np.add.reduceat(vHip_KO[mouse], range(0, vHip_KO[mouse].shape[0], 60))\n",
    "    \n",
    "    iteration += 1\n",
    "    \n",
    "tmean_KO=np.mean(t, axis=0)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(tx, tmean_WT, '-', color='blue', alpha=0.7)\n",
    "plt.plot(tx, tmean_KO, '-', color='red', alpha=0.7)\n",
    "plt.xticks([0, 20000, 40000, 60000, 80000, 100000, 120000], ['-3', '-2', '-1', '0', '1', '2', '3'], fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim([0,70])\n",
    "plt.axvline(x=60000, color='black')\n",
    "plt.xlabel('time (s)', fontsize=18)\n",
    "#plt.ylabel('units')\n",
    "plt.title('vHip', fontsize=24)\n",
    "\n",
    "\n",
    "plt.savefig('/home/maspe/filer/SERT/ALL/figs/perispikes.png', dpi=150, facecolor='w', edgecolor='w',\n",
    "            orientation='portrait', papertype=None, format='png', transparent=False)\n",
    "    \n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backup code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = []\n",
    "for unit in range(len(spikes_epochs_pre)):\n",
    "    # np.isin(element, test_elements)\n",
    "    spikes.append(np.isin(epoch_matrix, [spikes_epochs_pre[unit] + spikes_epochs_post[unit]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_epochs_pre = []\n",
    "spikes_epochs_post = []\n",
    "for unit in range(len(all_units)):\n",
    "    spiketimes_pre = []\n",
    "    spiketimes_post = []\n",
    "    for epoch in range(n_epochs):\n",
    "        spiketimes_pre.extend(all_units[unit][(all_units[unit] > epochs_pre[epoch][0]) & (all_units[unit] < epochs_post[epoch][1])])\n",
    "        spiketimes_post.extend(all_units[unit][(all_units[unit] > epochs_post[epoch][0]) & (all_units[unit] < epochs_post[epoch][1])])\n",
    "    spikes_epochs_pre.append(spiketimes_pre)\n",
    "    spikes_epochs_post.append(spiketimes_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spikes_epochs_pre[52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = []\n",
    "for unit in range(len(spikes_epochs_pre)):\n",
    "    # np.isin(element, test_elements)\n",
    "    spikes.append(np.isin(epoch_matrix, [spikes_epochs_pre[unit] + spikes_epochs_post[unit]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(spikes[50], axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Collect the name of channels, by mouse\n",
    "#all_units_WT = {}\n",
    "all_channels_WT = {}\n",
    "\n",
    "n_channels = 32\n",
    "for mouse in all_mice_WT.keys():\n",
    "\n",
    "    units = []\n",
    "    channels_id = []\n",
    "    \n",
    "    iteration = 0\n",
    "    for channel in range(n_channels):\n",
    "        for unit in all_mice_WT[mouse][channel]['spiketimes'].keys():\n",
    "            #units.append(all_mice_WT[mouse][channel]['spiketimes'][unit][()]) # Final \"[()]\" is to import values from h5py \n",
    "      \n",
    "            channels_id.append(all_info_WT[mouse]['channels_locs'][iteration])\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "            \n",
    "    #all_units_WT[mouse] = units\n",
    "    all_channels_WT[mouse] = channels_id\n",
    "        \n",
    "# print('n units = %i' %len(all_units))\n",
    "\n",
    "### Same for KOs\n",
    "#all_units_KO = {}\n",
    "all_channels_KO = {}\n",
    "for mouse in all_mice_KO.keys():\n",
    "    n_channels = 32\n",
    "    units = []\n",
    "    channels_id = []\n",
    "    \n",
    "    iteration = 0\n",
    "    for channel in range(n_channels):\n",
    "        for unit in all_mice_KO[mouse][channel]['spiketimes'].keys():\n",
    "            #units.append(all_mice_KO[mouse][channel]['spiketimes'][unit][()]) # Final \"[()]\" is to import values from h5py \n",
    "      \n",
    "            channels_id.append(all_info_KO[mouse]['channels_locs'][iteration])\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "            \n",
    "    #all_units_KO[mouse] = units\n",
    "    all_channels_KO[mouse] = channels_id\n",
    "        \n",
    "# print('n units = %i' %len(all_units))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

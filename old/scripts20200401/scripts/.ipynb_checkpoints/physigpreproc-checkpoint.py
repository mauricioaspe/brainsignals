{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Created on Tue May 14 15:39:09 2019\n",
    "\n",
    "@author: mauro\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "\n",
    "\n",
    "def loadContinuous(filepath, dtype=float, verbose=True, \n",
    "    start_record=None, stop_record=None, ignore_last_record=True):\n",
    "    \"\"\"Load continuous data from a single channel in the file `filepath`.\n",
    "    \n",
    "    This is intended to be mostly compatible with the previous version.\n",
    "    The differences are:\n",
    "    - Ability to specify start and stop records\n",
    "    - Converts numeric data in the header from string to numeric data types\n",
    "    - Does not rely on a predefined maximum data size\n",
    "    - Does not necessarily drop the last record, which is usually incomplete\n",
    "    - Uses the block length that is specified in the header, instead of\n",
    "        hardcoding it.\n",
    "    - Returns timestamps and recordNumbers as int instead of float\n",
    "    - Tests the record metadata (N and record marker) for internal consistency\n",
    "    The OpenEphys file format breaks the data stream into \"records\", \n",
    "    typically of length 1024 samples. There is only one timestamp per record.\n",
    "    Args:\n",
    "        filepath : string, path to file to load\n",
    "        dtype : float or np.int16\n",
    "            If float, then the data will be multiplied by bitVolts to convert\n",
    "            to microvolts. This increases the memory required by 4 times.\n",
    "        verbose : whether to print debugging messages\n",
    "        start_record, stop_record : indices that control how much data\n",
    "            is read and returned. Pythonic indexing is used,\n",
    "            so `stop_record` is not inclusive. If `start` is None, reading\n",
    "            begins at the beginning; if `stop` is None, reading continues\n",
    "            until the end.\n",
    "        ignore_last_record : The last record in the file is almost always\n",
    "            incomplete (padded with zeros). By default it is ignored, for\n",
    "            compatibility with the old version of this function.\n",
    "    Returns: dict, with following keys\n",
    "        data : array of samples of data\n",
    "        header : the header info, as returned by readHeader\n",
    "        timestamps : the timestamps of each record of data that was read\n",
    "        recordingNumber : the recording number of each record of data that\n",
    "            was read. The length is the same as `timestamps`.\n",
    "    \"\"\"\n",
    "    if dtype not in [float, np.int16]:\n",
    "        raise ValueError(\"Invalid data type. Must be float or np.int16\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Loading continuous data from \" + filepath)\n",
    "\n",
    "    \"\"\"Here is the OpenEphys file format:\n",
    "    'each record contains one 64-bit timestamp, one 16-bit sample \n",
    "    count (N), 1 uint16 recordingNumber, N 16-bit samples, and \n",
    "    one 10-byte record marker (0 1 2 3 4 5 6 7 8 255)'\n",
    "    Thus each record has size 2*N + 22 bytes.\n",
    "    \"\"\"\n",
    "    # This is what the record marker should look like\n",
    "    spec_record_marker = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 255])\n",
    "\n",
    "    # Lists for data that's read\n",
    "    timestamps = []\n",
    "    recordingNumbers = []\n",
    "    samples = []\n",
    "    samples_read = 0\n",
    "    records_read = 0\n",
    "    \n",
    "    # Open the file\n",
    "    with open(filepath, 'rb') as f:\n",
    "        # Read header info, file length, and number of records\n",
    "        header = readHeader(f)\n",
    "        record_length_bytes = 2 * header['blockLength'] + 22\n",
    "        fileLength = os.fstat(f.fileno()).st_size\n",
    "        n_records = get_number_of_records(filepath)\n",
    "        \n",
    "        # Use this to set start and stop records if not specified\n",
    "        if start_record is None:\n",
    "            start_record = 0\n",
    "        if stop_record is None:\n",
    "            stop_record = n_records\n",
    "        \n",
    "        # We'll stop reading after this many records are read\n",
    "        n_records_to_read = stop_record - start_record\n",
    "        \n",
    "        # Seek to the start location, relative to the current position\n",
    "        # right after the header.\n",
    "        f.seek(record_length_bytes * start_record, 1)\n",
    "        \n",
    "        # Keep reading till the file is finished\n",
    "        while f.tell() < fileLength and records_read < n_records_to_read:\n",
    "            # Skip the last record if requested, which usually contains\n",
    "            # incomplete data\n",
    "            if ignore_last_record and f.tell() == (\n",
    "                fileLength - record_length_bytes):\n",
    "                break\n",
    "            \n",
    "            # Read the timestamp for this record\n",
    "            # litte-endian 64-bit signed integer\n",
    "            timestamps.append(np.fromfile(f, np.dtype('<i8'), 1))\n",
    "        \n",
    "            # Read the number of samples in this record\n",
    "            # little-endian 16-bit unsigned integer\n",
    "            N = np.fromfile(f, np.dtype('<u2'), 1).item() \n",
    "            if N != header['blockLength']:\n",
    "                raise IOError('Found corrupted record in block ' + \n",
    "                    str(recordNumber))\n",
    "            \n",
    "            # Read and store the recording numbers\n",
    "            # big-endian 16-bit unsigned integer\n",
    "            recordingNumbers.append(np.fromfile(f, np.dtype('>u2'), 1))\n",
    "            \n",
    "            # Read the data\n",
    "            # big-endian 16-bit signed integer\n",
    "            data = np.fromfile(f, np.dtype('>i2'), N)\n",
    "            if len(data) != N:\n",
    "                raise IOError(\"could not load the right number of samples\")\n",
    "            \n",
    "            # Optionally convert dtype\n",
    "            if dtype == float: \n",
    "                data = data * header['bitVolts']\n",
    "                        \n",
    "            # Store the data\n",
    "            samples.append(data)\n",
    "\n",
    "            # Extract and test the record marker\n",
    "            record_marker = np.fromfile(f, np.dtype('<u1'), 10)\n",
    "            if np.any(record_marker != spec_record_marker):\n",
    "                raise IOError(\"corrupted record marker at record %d\" %\n",
    "                    records_read)\n",
    "            \n",
    "            # Update the count\n",
    "            samples_read += len(samples)            \n",
    "            records_read += 1\n",
    "\n",
    "    # Concatenate results, or empty arrays if no data read (which happens\n",
    "    # if start_sample is after the end of the data stream)\n",
    "    res = {'header': header}\n",
    "    if samples_read > 0:\n",
    "        res['timestamps'] = np.concatenate(timestamps)\n",
    "        res['data'] = np.concatenate(samples)\n",
    "        res['recordingNumber'] = np.concatenate(recordingNumbers)\n",
    "    else:\n",
    "        res['timestamps'] = np.array([], dtype=np.int)\n",
    "        res['data'] = np.array([], dtype=dtype)\n",
    "        res['recordingNumber'] = np.array([], dtype=np.int)\n",
    "    return res\n",
    "\n",
    "\n",
    "def readHeader(f):\n",
    "    \"\"\"Read header information from the first 1024 bytes of an OpenEphys file.\n",
    "    \n",
    "    Args:\n",
    "        f: An open file handle to an OpenEphys file\n",
    "    \n",
    "    Returns: dict with the following keys.\n",
    "        - bitVolts : float, scaling factor, microvolts per bit\n",
    "        - blockLength : int, e.g. 1024, length of each record (see \n",
    "            loadContinuous)\n",
    "        - bufferSize : int, e.g. 1024\n",
    "        - channel : the channel, eg \"'CH1'\"\n",
    "        - channelType : eg \"'Continuous'\"\n",
    "        - date_created : eg \"'15-Jun-2016 21212'\" (What are these numbers?)\n",
    "        - description : description of the file format\n",
    "        - format : \"'Open Ephys Data Format'\"\n",
    "        - header_bytes : int, e.g. 1024\n",
    "        - sampleRate : float, e.g. 30000.\n",
    "        - version: eg '0.4'\n",
    "        Note that every value is a string, even numeric data like bitVolts.\n",
    "        Some strings have extra, redundant single apostrophes.\n",
    "    \"\"\"\n",
    "    header = {}\n",
    "    \n",
    "    # Read the data as a string\n",
    "    # Remove newlines and redundant \"header.\" prefixes\n",
    "    # The result should be a series of \"key = value\" strings, separated\n",
    "    # by semicolons.\n",
    "    header_string = f.read(1024).decode().replace('\\n','').replace('header.','')\n",
    "    \n",
    "    # Parse each key = value string separately\n",
    "    for pair in header_string.split(';'):\n",
    "        if '=' in pair:\n",
    "            key, value = pair.split(' = ')\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "            \n",
    "            # Convert some values to numeric\n",
    "            if key in ['bitVolts', 'sampleRate']:\n",
    "                header[key] = float(value)\n",
    "            elif key in ['blockLength', 'bufferSize', 'header_bytes']:\n",
    "                header[key] = int(value)\n",
    "            else:\n",
    "                # Keep as string\n",
    "                header[key] = value\n",
    "\n",
    "    return header\n",
    "\n",
    "    \n",
    "def downsample(trace,down):\n",
    "    downsampled = scipy.signal.resample(trace,np.shape(trace)[0]/down)\n",
    "    return downsampled\n",
    "\n",
    "\n",
    "def get_number_of_records(filepath):\n",
    "    # Open the file\n",
    "    with open(filepath, 'rb') as f:\n",
    "        # Read header info\n",
    "        header = readHeader(f)\n",
    "        \n",
    "        # Get file length\n",
    "        fileLength = os.fstat(f.fileno()).st_size\n",
    "        \n",
    "        # Determine the number of records\n",
    "        record_length_bytes = 2 * header['blockLength'] + 22\n",
    "        n_records = int((fileLength - 1024) / record_length_bytes)\n",
    "        if (n_records * record_length_bytes + 1024) != fileLength:\n",
    "            raise IOError(\"file does not divide evenly into full records\")\n",
    "    \n",
    "    return n_records\n",
    "\n",
    "def filtering(signal):\n",
    "    scipy.signal.butter(N, Wn, btype='low', analog=False, output='ba') \n",
    "    scipy.signal.filtfilt(b, a, x, axis=-1, padtype='odd', padlen=None, method='pad', irlen=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

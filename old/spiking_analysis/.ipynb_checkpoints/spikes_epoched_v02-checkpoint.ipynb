{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "#import pandas as pd\n",
    "#import wavelets as wl\n",
    "#from scipy import signal\n",
    "#from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a dictionary with mice's experiment information and another with the spiking activity in h5py format  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing wild-types...\n",
      "Loading SERT1597\n",
      "Loading SERT1659\n",
      "Loading SERT1678\n",
      "Loading SERT1908\n",
      "Loading SERT1984\n",
      "Loading SERT1985\n",
      "Loading SERT2014\n",
      "Processing knock-outs...\n",
      "Loading SERT1668\n",
      "Loading SERT1665\n",
      "Loading SERT2013\n",
      "Loading SERT2018\n",
      "Loading SERT2024\n",
      "Saving channels info for spiking analysis...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# List of mice, classified by condition\n",
    "IDs_WT = ['SERT1597', 'SERT1659', 'SERT1678', 'SERT1908', 'SERT1984', 'SERT1985', 'SERT2014']\n",
    "IDs_KO = ['SERT1668', 'SERT1665', 'SERT2013', 'SERT2018', 'SERT2024']\n",
    "\n",
    "# Dictionaries to collect info about the experiment and spiking activity\n",
    "all_units_WT = {}\n",
    "all_channels_WT = {}\n",
    "all_units_KO = {}\n",
    "all_channels_KO = {}\n",
    "\n",
    "all_info_WT = {}\n",
    "all_mice_WT = {}\n",
    "all_info_KO = {}\n",
    "all_mice_KO = {}\n",
    "\n",
    "n_channels = 32\n",
    "    \n",
    "print('Processing wild-types...')\n",
    "for ID in IDs_WT:\n",
    "    npys_dir = '/home/maspe/filer/SERT/' + ID + '/npys/'\n",
    "    spikes_dir = '/home/maspe/filer/SERT/' + ID + '/spikes/results/'\n",
    "    \n",
    "    print('Loading ' + ID)\n",
    "    with open(npys_dir + ID + '.info', 'rb') as f:\n",
    "        info = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "    # Put the info of this mouse into de info dictionary\n",
    "    all_info_WT[ID] = info\n",
    "    channels = info['channels_list']\n",
    "    \n",
    "    fit = []\n",
    "    for channel in channels:\n",
    "        path = spikes_dir + channel + '.result.hdf5'\n",
    "    \n",
    "        # Get the spiking activity from the h5py file\n",
    "        fit.append(h5py.File(path, 'r'))\n",
    "        \n",
    "     \n",
    "    # Put the spiking activity of this mouse into the spiking dictionary\n",
    "    all_mice_WT[ID] = fit\n",
    "    \n",
    "    \n",
    "    ########################\n",
    "    units = []\n",
    "    channels_id = []\n",
    "    \n",
    "    iteration = 0\n",
    "    for channel in range(n_channels):\n",
    "        for unit in all_mice_WT[ID][channel]['spiketimes'].keys():\n",
    "            units.append(all_mice_WT[ID][channel]['spiketimes'][unit][()]) # Final \"[()]\" is to import values from h5py \n",
    "      \n",
    "            channels_id.append(all_info_WT[ID]['channels_locs'][iteration])\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "            \n",
    "    all_units_WT[ID] = units\n",
    "    all_channels_WT[ID] = channels_id\n",
    "    \n",
    "    \n",
    "### Same for KO mice\n",
    "#print('Processing knock-out')\n",
    "print('Processing knock-outs...')\n",
    "for ID in IDs_KO:\n",
    "    npys_dir = '/home/maspe/filer/SERT/' + ID + '/npys/'\n",
    "    spikes_dir = '/home/maspe/filer/SERT/' + ID + '/spikes/results/'\n",
    "    \n",
    "    print('Loading ' + ID)\n",
    "    with open(npys_dir + ID + '.info', 'rb') as f:\n",
    "        info = pickle.load(f, encoding='latin1')\n",
    "\n",
    "    all_info_KO[ID] = info\n",
    "    channels = info['channels_list']\n",
    "    \n",
    "    fit = []\n",
    "    for channel in channels:\n",
    "        path = spikes_dir + channel + '.result.hdf5'\n",
    "    \n",
    "        fit.append(h5py.File(path, 'r'))\n",
    "                \n",
    "    all_mice_KO[ID] = fit\n",
    "    \n",
    "    \n",
    "    ########################\n",
    "    units = []\n",
    "    channels_id = []\n",
    "    \n",
    "    iteration = 0\n",
    "    for channel in range(n_channels):\n",
    "        for unit in all_mice_KO[ID][channel]['spiketimes'].keys():\n",
    "            units.append(all_mice_KO[ID][channel]['spiketimes'][unit][()]) # Final \"[()]\" is to import values from h5py \n",
    "      \n",
    "            channels_id.append(all_info_KO[ID]['channels_locs'][iteration])\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "            \n",
    "    all_units_KO[ID] = units\n",
    "    all_channels_KO[ID] = channels_id\n",
    "    #########################\n",
    "\n",
    "# Saving channels info for spiking analysis\n",
    "print('Saving channels info for spiking analysis...')\n",
    "\n",
    "with open('/home/maspe/filer/SERT/ALL/npys/channels_by_spikes_WT.info', 'wb') as f:\n",
    "    pickle.dump(all_channels_WT, f, protocol=2)\n",
    "with open('/home/maspe/filer/SERT/ALL/npys/channels_by_spikes_KO.info', 'wb') as f:\n",
    "    pickle.dump(all_channels_KO, f, protocol=2)\n",
    "\n",
    "\n",
    "\n",
    "print('Done!')\n",
    "    \n",
    "# all_mice_WT['SERT1597'][0]['spiketimes']['temp_0'][()].shape\n",
    "# all_units_WT['SERT1597']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the windows of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are currently using a time windows of 2 minutes that finishes 15 seconds before the beginning of the OF, for the HC condition; and a time windows that begins 15 seconds after the beginning of the OF, and extends to minute 10 (total length: 9.75 min)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS CAN BE MOVED TO THE CREATION OF INFO FILES!!! ###\n",
    "### Extract a windows of n_secs length at the beginning and end of the task\n",
    "n_min = 2\n",
    "exclude_sec = 15\n",
    "sample_rate = 30000\n",
    "#window = int(sampleRate * secs)\n",
    "n_points = 30000 * 60 * 10 # Length of the OF\n",
    "window = sample_rate * n_min * 60 # 2 min windows\n",
    "exclude_window = sample_rate * exclude_sec # 15 sec windows to exclude at the HC-OF transition\n",
    "\n",
    "all_epochs_WT = {}\n",
    "all_perispikes_WT = {}\n",
    "for mouse in all_mice_WT.keys():\n",
    "    stopHC = np.int(all_info_WT[mouse]['startOF']) - exclude_window\n",
    "    startHC = stopHC - window\n",
    "    \n",
    "    startOF = np.int(all_info_WT[mouse]['startOF']) + exclude_window\n",
    "    stopOF = startOF + n_points - exclude_window\n",
    "    \n",
    "    baseline = np.arange(startHC, stopHC, 1)\n",
    "    task = np.arange(startOF, stopOF, 1)\n",
    "    \n",
    "    complete_window = np.concatenate([baseline, task])\n",
    "    all_epochs_WT[mouse] = complete_window\n",
    "    \n",
    "\n",
    "all_epochs_KO = {}\n",
    "all_perispikes_KO = {}\n",
    "for mouse in all_mice_KO.keys():\n",
    "    stopHC = np.int(all_info_KO[mouse]['startOF']) - exclude_window\n",
    "    startHC = stopHC - window\n",
    "    \n",
    "    startOF = np.int(all_info_KO[mouse]['startOF']) + exclude_window\n",
    "    stopOF = startOF + n_points - exclude_window\n",
    "    \n",
    "    baseline = np.arange(startHC, stopHC, 1)\n",
    "    task = np.arange(startOF, stopOF, 1)\n",
    "    \n",
    "    complete_window = np.concatenate([baseline, task])\n",
    "    all_epochs_KO[mouse] = complete_window\n",
    "\n",
    "\n",
    "task_npoints = complete_window.shape[0]\n",
    "print('Windows of interest created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the spikes that fall inside the time windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For WT\n",
    "all_perispikes_WT = {}\n",
    "npys_dir = '/home/maspe/filer/SERT/ALL/npys/'\n",
    "\n",
    "print('Loading WTs')\n",
    "clock = time.time()\n",
    "for mouse in all_mice_WT.keys():\n",
    "    all_spikes = all_units_WT[mouse]\n",
    "    peristimulus_spikes = np.zeros((len(all_spikes), task_npoints))   \n",
    "    \n",
    "    print('Processing mouse %s...' % mouse)\n",
    "    \n",
    "    for unit in range(len(all_spikes)):\n",
    "        peristimulus_spikes[unit, :] = np.isin(all_epochs_WT[mouse], all_spikes[unit])\n",
    "        \n",
    "        \n",
    "    all_perispikes_WT[mouse] = peristimulus_spikes\n",
    "    np.save(npys_dir + mouse + '_spikes_WT.npy', peristimulus_spikes)\n",
    "    \n",
    "print('WTs done in {} min.!'.format((time.time() - clock) / 60))\n",
    "\n",
    "### For KO\n",
    "all_perispikes_KO = {}\n",
    "      \n",
    "print('Loading KOs')\n",
    "clock = time.time()\n",
    "for mouse in all_mice_KO.keys():\n",
    "    all_spikes = all_units_KO[mouse] \n",
    "    peristimulus_spikes = np.zeros((len(all_spikes), task_npoints))   \n",
    "    \n",
    "    print('Processing mouse %s...' % mouse)\n",
    "\n",
    "    for unit in range(len(all_spikes)):\n",
    "        peristimulus_spikes[unit, :] = np.isin(all_epochs_KO[mouse], all_spikes[unit])\n",
    "\n",
    "        \n",
    "    all_perispikes_KO[mouse] = peristimulus_spikes\n",
    "    np.save(npys_dir + mouse + '_spikes_KO.npy', peristimulus_spikes)\n",
    "    \n",
    "print('KO done in {} min.!'.format((time.time() - clock) / 60)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script finished on 2020-03-23 at 22:47:17\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Script finished in {} at {}\".format(date.today(), current_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(all_perispikes_KO['SERT1668'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
